{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3af66be5",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "Deep Learning techniques can be used to predict various outcomes including but not limited to future sales. Your task is to create a deep learning model of the Long Short Term Memory which is a type of Recurrent Neural Network .\n",
    "\n",
    "You can use either Tensorflow or Pytorch libraries for model building. The model should not be very deep (Two layers) due to the computational requirements, it should comfortably run in google colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504bed17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing of libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib import ticker\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import seaborn as sns\n",
    "import os,sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from timeseries import TimeSeries\n",
    "from modeling import Modeler\n",
    "sns.set()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd91e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ = pd.read_csv(\"../data/cleaned_train.csv\")\n",
    "test = pd.read_csv(\"../data/cleaned_test.csv\")\n",
    "train_.drop(['DayOfWeek','DayOfYear','WeekOfYear',\n",
    "            'Customers',\"Month\",\"Day\"],axis=1,inplace=True)\n",
    "test.drop([\"Id\",'DayOfWeek','DayOfYear','WeekOfYear'\n",
    "           ,\"Month\",\"Day\"],axis=1,inplace=True)\n",
    "train=train_.loc[:,train_.columns!='Sales']\n",
    "train['Sales']=train_['Sales']\n",
    "train.sort_values([\"Year\"], ascending=False ,ignore_index=True, inplace=True)\n",
    "test.sort_values([\"Year\"], ascending=False ,ignore_index=True, inplace=True)\n",
    "train.index.name = 'Year'\n",
    "train = train.set_index('Year')\n",
    "test.index.name = 'Year'\n",
    "test = test.set_index('Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d73445e",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "- Isolate the Rossmann Store Sales dataset into time series data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866bbdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 11:57:54,872:logger:Initialized the time series class\n"
     ]
    }
   ],
   "source": [
    "timeseries = TimeSeries(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d4b993",
   "metadata": {},
   "source": [
    "- Check whether your time Series Data is Stationary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93106a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timeseries.perform_adfuller('Sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce439a12",
   "metadata": {},
   "source": [
    "- Depending on your conclusion from 2 above difference your time series data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda424a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Sales'] = timeseries.remove_stationarity(train.Sales.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d0e07e",
   "metadata": {},
   "source": [
    "- Check for autocorrelation and partial autocorrelation of your data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bf3e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acfSalesScaled = acf(train.Sales.values, fft=True, nlags=40)\n",
    "acfSalesScaledArray = np.array(acfSalesScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52eebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries.corrPlots(acfSalesScaledArray, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c6104d",
   "metadata": {},
   "source": [
    "- Transform the time series data into supervised learning data by creating a new y(target) column. For example as illustrated here in the Sliding Window For Time Series Data section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81dcf47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = len(train.Sales)\n",
    "WINDOW_SIZE = 48\n",
    "BATCH_SIZE= SIZE-WINDOW_SIZE*2\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b532826f",
   "metadata": {},
   "source": [
    "- Scale your data in the (-1, 1) range\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80330b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 12:00:47,359:logger:Successfully windowed the dataset\n",
      "2022-05-25 12:00:47,422:logger:Successfully windowed the dataset\n"
     ]
    }
   ],
   "source": [
    "DatasetTrain = timeseries.split_dataset(train.Sales[0:BATCH_SIZE])\n",
    "DatasetVal = timeseries.split_dataset(train.Sales[:BATCH_SIZE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b13ae38",
   "metadata": {},
   "source": [
    "- Build a LSTM Regression model to predict the next sale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb6695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 12:01:04,584:logger:Successfully modeled the neural network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1621/1621 [==============================] - 279s 167ms/step - loss: 2.4613e-05 - val_loss: 0.0015\n",
      "Epoch 2/5\n",
      " 542/1621 [=========>....................] - ETA: 1:56 - loss: 6.6099e-05"
     ]
    }
   ],
   "source": [
    "model = timeseries.model()\n",
    "results = model.fit(DatasetTrain, epochs=EPOCHS, validation_data=DatasetVal, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d0884",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = timeseries.model_forecast(model, train.Sales.values[:, np.newaxis], WINDOW_SIZE,SIZE=BATCH_SIZE)\n",
    "results = forecast[BATCH_SIZE-WINDOW_SIZE:-1]\n",
    "results_ = scaler.inverse_transform(results.reshape(-1,1))\n",
    "XValid_ = scaler.inverse_transform(XValid.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee137ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_forecast_= timeseries.view_forecast(DateValid,XValid_,results_,results,WINDOW_SIZE=48)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
