{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dd8e0fb",
   "metadata": {},
   "source": [
    "# Preparing data\n",
    "Prediction of sales is the central task in this challenge. you want to predict daily sales in various stores up to 6 weeks ahead of time. This will help the company plan ahead of time. \n",
    "\n",
    "The following steps outline the various sub tasks needed to effectively do this: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef789c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 04:46:28.004293: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-25 04:46:28.004422: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/martin/Documents/pharm_sales/notebooks\n"
     ]
    }
   ],
   "source": [
    "# importing of libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "import os,sys\n",
    "sys.path.append(os.path.abspath(os.path.join('../scripts')))\n",
    "from timeseries import TimeSeries\n",
    "from clean import Clean\n",
    "sns.set()\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d701d93",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "It is important to process the data into a format where it can be fed to a machine learning model. This typically means converting all non-numeric columns to numeric, handling NaN values and generating new features from already existing features. \n",
    "\n",
    "In our case, you have a few datetime columns to preprocess. you can extract the following from them:\n",
    "weekdays\n",
    "weekends \n",
    "number of days to holidays\n",
    "Number of days after holiday\n",
    "Beginning of month, mid month and ending of month\n",
    "(think of more features to extract), extra marks for it\n",
    "            \n",
    "As a final thing, you have to scale the data. This helps with predictions especially when using machine learning algorithms that use Euclidean distances. you can use the standard scaler in sklearn for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd76c480",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8234/2395586539.py:2: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"../data/train.csv\")\n",
      "2022-05-25 04:46:40,391:logger:Successfully initialized clean class\n",
      "2022-05-25 04:46:40,774:logger:Successfully merged the dataframe\n",
      "2022-05-25 04:46:48,947:logger:Successfully saved the dataframe\n",
      "2022-05-25 04:46:50,517:logger:Successfully dropped the columns with missing values\n",
      "2022-05-25 04:46:50,532:logger:Successfully stored the features\n",
      "2022-05-25 04:46:50,592:logger:Successfully handled outliers\n",
      "2022-05-25 04:46:50,640:logger:Successfully removed columns with head unnamed\n",
      "2022-05-25 04:46:51,338:logger:Successfully transformed data to time series data\n",
      "2022-05-25 04:46:57,764:logger:Successfully saved the dataframe\n"
     ]
    }
   ],
   "source": [
    "store = pd.read_csv(\"../data/store.csv\")\n",
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "clean_df = Clean(df)\n",
    "clean_df.merge_df(store,'Store')\n",
    "clean_df.save(name='../data/unclean_train.csv')\n",
    "clean_df.drop_missing_values()\n",
    "clean_df.fix_outliers('Sales',25000)\n",
    "clean_df.remove_unnamed_cols()\n",
    "clean_df.transfrom_time_series(\"Store\",\"Date\")\n",
    "clean_df.save(name=\"../data/training.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f9ed6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 04:46:58,001:logger:Successfully initialized clean class\n",
      "2022-05-25 04:46:58,020:logger:Successfully merged the dataframe\n",
      "2022-05-25 04:46:58,343:logger:Successfully saved the dataframe\n",
      "2022-05-25 04:46:58,393:logger:Successfully dropped the columns with missing values\n",
      "2022-05-25 04:46:58,394:logger:Successfully stored the features\n",
      "2022-05-25 04:46:58,396:logger:Successfully handled outliers\n",
      "2022-05-25 04:46:58,402:logger:Successfully removed columns with head unnamed\n",
      "2022-05-25 04:46:58,477:logger:Successfully transformed data to time series data\n",
      "2022-05-25 04:46:58,752:logger:Successfully saved the dataframe\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/test.csv\")\n",
    "clean_df = Clean(df)\n",
    "clean_df.merge_df(store,'Store')\n",
    "clean_df.save(name='../data/unclean_test.csv')\n",
    "clean_df.drop_missing_values()\n",
    "clean_df.fix_outliers('Sales',25000)\n",
    "clean_df.remove_unnamed_cols()\n",
    "clean_df.transfrom_time_series(\"Store\",\"Date\")\n",
    "clean_df.save(name=\"../data/testing.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21281ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../data/training.csv\")\n",
    "test = pd.read_csv(\"../data/testing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a26439",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457b8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 04:46:59,588:logger:successful aggregation\n",
      "2022-05-25 04:46:59,612:logger:successful aggregation\n",
      "2022-05-25 04:46:59,683:logger:successful aggregation\n",
      "2022-05-25 04:46:59,708:logger:successful aggregation\n"
     ]
    }
   ],
   "source": [
    "daily_sales = clean_df.aggregations(train,'Store','Sales','Open','sum')\n",
    "daily_customers = clean_df.aggregations(train,'Store','Customers','Open','sum')\n",
    "avg_sales = clean_df.aggregations(train,'Store','Sales','Open','mean')\n",
    "avg_customers = clean_df.aggregations(train,'Store','Customers','Open','mean')\n",
    "train['DailySales'] = train['Store'].map(daily_sales)\n",
    "train['DailyCustomers'] = train['Store'].map(daily_customers)\n",
    "train['AvgSales'] = train['Store'].map(avg_sales)\n",
    "train['AvgCustomers'] = train['Store'].map(avg_customers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37f6a4",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c934305c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 04:46:59,750:logger:Successfully stored the features\n",
      "2022-05-25 04:47:00,279:logger:Successfully encoded your categorical data\n"
     ]
    }
   ],
   "source": [
    "clean_df.label_encoding(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e83efa",
   "metadata": {},
   "source": [
    "Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebe7e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_ = train[train.columns.difference(['DayOfWeek','Day', 'Month', 'Year', 'DayOfYear','WeekOfYear'])]\n",
    "testing_data_ = test[test.columns.difference(['DayOfWeek','Day', 'Month', 'Year', 'DayOfYear','WeekOfYear'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d6e6689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-25 04:47:00,646:logger:Successfully transformed numerical data\n",
      "2022-05-25 04:47:00,664:logger:Successfully transformed numerical data\n"
     ]
    }
   ],
   "source": [
    "train_transformation=clean_df.generate_transformation(training_data_,\"numeric\",\"number\")\n",
    "test_transformation=clean_df.generate_transformation(testing_data_,\"numeric\",\"number\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8b9bc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = ['DayOfWeek','Day', 'Month', 'Year', 'DayOfYear','WeekOfYear']\n",
    "train_transformed = pd.DataFrame(train_transformation,columns=train.columns.difference(indexes))\n",
    "test_transformed = pd.DataFrame(test_transformation,columns=test.columns.difference(indexes))\n",
    "train_index = train[indexes]\n",
    "test_index = test[indexes]\n",
    "train = pd.concat([train_index,train_transformed],axis=1)\n",
    "test = pd.concat([test_index,test_transformed],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "628bb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values([\"Year\",\"Month\",\"Day\"], ascending=False ,ignore_index=True, inplace=True)\n",
    "test.sort_values([\"Year\",\"Month\",\"Day\"], ascending=False ,ignore_index=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "295885cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/cleaned_train.csv\",index=False)\n",
    "test.to_csv(\"../data/cleaned_test.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749ca3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
